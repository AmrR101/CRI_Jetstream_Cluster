---

- hosts: localhost

  vars:
    compute_base_image: "JS-API-Featured-CentOS7-Dec-14-2018"
    sec_group_global: "global-ssh"
    sec_group_internal: "cluster-internal"
    compute_base_size: "m1.small"
    network_name: "{{ clouds.tacc.auth.username }}-elastic-net"
    JS_ssh_keyname: "{{ clouds.tacc.auth.username }}-{{ clouds.tacc.auth.project_name }}-slurm-key"

  vars_files:
    - clouds.yaml

  tasks:

  - name: build compute base instance 
    os_server:
      timeout: 200
      state: present
      name: "compute-{{ clouds.tacc.auth.username }}-base-instance"
      cloud: "tacc"
      image: "{{ compute_base_image }}"
      key_name: "{{ JS_ssh_keyname }}"
      security_groups: "{{ sec_group_global }},{{ sec_group_internal }}"
      flavor: "{{ compute_base_size }}"
      meta: { compute: "base" }
      auto_ip: "no"
      network: "{{ network_name }}"
      wait: yes
    register: "os_host"

  - debug:
      var: os_host

  - name: add compute instance to inventory
    add_host:
      name: "{{ os_host['openstack']['name'] }}"
      groups: "compute-base"
      ansible_host: "{{ os_host.openstack.private_v4 }}"

  - name: pause for ssh to come up
    pause:
      seconds: 90


- hosts: compute-base

  vars:
    compute_base_package_list:
      - "openmpi"       
      - "libselinux-python"
      - "telnet"
      - "bind-utils"
      - "vim"
      - "ohpc-slurm-client"
      - "lmod-ohpc"

  tasks:

  - name: Get the headnode private IP
    local_action:
      module: shell ip addr | grep -Eo '10.0.0.[0-9]*' | head -1
    register: headnode_private_ip
    become: False # for running as slurm, since no sudo on localhost

  - name: Get the slurmctld uid
    local_action:
      module: shell getent passwd slurm | awk -F':' '{print $3}'
    register: headnode_slurm_uid
    become: False # for running as slurm, since no sudo on localhost

  - name: Add OpenHPC 1.3.5 repo
    yum:
      name: "https://github.com/openhpc/ohpc/releases/download/v1.3.GA/ohpc-release-1.3-1.el7.x86_64.rpm"
      state: present

  - name: install basic packages
    yum: 
      name: "{{ compute_base_package_list }}" 
      state: present
 #    - "quantum-espresso-openmpi"
 #    - "quantum-espresso"
 #     - "rsync"
 #     - "epel-release"
 #     - "openmpi-devel"       #torque
 #     - "gcc"           
 #     - "gcc-c++"       
 #     - "gcc-gfortran"  
 #     - "openssl-devel" 
 #     - "libxml2-devel" 
 #     - "boost-devel"   
 #     - "net-tools"
 #     - "strace"
 #     - "wget"  # needed for building QE
 #     - "readline-devel"  #req for slurm
 #     - "pam-devel"       # req for slurm
 #     - "perl-ExtUtils-MakeMaker" # req for slurm
 #     - "fftw" # req for QE... need a better way to specify these!!!
 #

  - name: fix slurm user uid
    user:
      name: slurm
      uid: "{{ headnode_slurm_uid.stdout}}"
      shell: "/sbin/nologin"
      home: "/etc/slurm"

  - name: change ownership of slurm files
    file:
      path: "{{ item }}"
      owner: slurm
      group: slurm
    with_items:
      - "/var/log/slurm_jobacct.log"
      - "/var/spool/slurm"
      - "/var/spool/slurm/ctld"

  - name: disable selinux
    selinux: state=permissive policy=targeted

 # - name: allow use_nfs_home_dirs
 #   seboolean: name=use_nfs_home_dirs state=yes persistent=yes

  - name: import /home on compute nodes
    lineinfile:
      dest: /etc/fstab
      line:  "{{ headnode_private_ip.stdout }}:/home  /home  nfs  defaults,nfsvers=4.0 0 0"
      state: present

  - name: ensure /opt/ohpc/pub exists
    file: path=/opt/ohpc/pub state=directory mode=777 recurse=yes
 
  - name: import /opt/ohpc/pub on compute nodes
    lineinfile:
      dest: /etc/fstab
      line:  "{{ headnode_private_ip.stdout }}:/opt/ohpc/pub  /opt/ohpc/pub  nfs  defaults,nfsvers=4.0 0 0"
      state: present

  - name: ensure /export exists
    file: path=/export state=directory mode=777
 
  - name: import /export on compute nodes
    lineinfile:
      dest: /etc/fstab
      line:  "{{ headnode_private_ip.stdout }}:/export  /export  nfs  defaults,nfsvers=4.0 0 0"
      state: present

  - name: fix sda1 mount in fstab
    lineinfile:
      dest: /etc/fstab
      regex: "/                       xfs     defaults"
      line: "/dev/sda1           /                       xfs     defaults  0 0"
      state: present
 
#  - name: add local users to compute node
#    script: /tmp/add_users.sh
#    ignore_errors: True

  - name: copy munge key from headnode
    synchronize:
      mode: push
      src: /etc/munge/munge.key
      dest: /etc/munge/munge.key
      set_remote_user: no
      use_ssh_args: yes

  - name: fix perms on munge key
    file: 
      path: /etc/munge/munge.key
      owner: munge
      group: munge
      mode: 0600
 
  - name: copy slurm.conf from headnode
    synchronize:
      mode: push
      src: /etc/slurm/slurm.conf
      dest: /etc/slurm/slurm.conf
      set_remote_user: no
      use_ssh_args: yes
 
  - name: copy slurm_prolog.sh from headnode
    synchronize:
      mode: push
      src: /usr/local/sbin/slurm_prolog.sh
      dest: /usr/local/sbin/slurm_prolog.sh
      set_remote_user: no
      use_ssh_args: yes
 
  - name: enable munge
    service: name=munge.service enabled=yes 
 
  - name: enable slurmd
    service: name=slurmd enabled=yes

#  - name: mount -a on compute nodes
#    command: "mount -a"

- hosts: localhost

  vars_files:
    - clouds.yaml

  tasks:

  - name: create compute instance snapshot
    script: ./compute_take_snapshot.sh

  - name: remove compute instance
    os_server:
      timeout: 200
      state: absent
      name: "compute-{{ clouds.tacc.auth.username }}-base-instance"
      cloud: "tacc"
